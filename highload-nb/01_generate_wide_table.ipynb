{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "The data analysis is crucial for the understanding of the raw counter/KPI dataset. It includes some data pre-processing (removing invalid entries, missing data handling, etc.) as well as analysis on the counter/KPIs statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"data/data_wide_min_max.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  12/18/2018\n",
       "1                           0\n",
       "2                         NaN\n",
       "3         0.16597813033539074\n",
       "4         0.18917366324749751\n",
       "5          0.2956798128111791\n",
       "6           0.649423951404181\n",
       "7         0.12399756110890493\n",
       "8          0.2694785531892605\n",
       "9         0.42967878597881326\n",
       "10         0.4953081238983578\n",
       "11         0.3119579702849906\n",
       "12          0.270747998056189\n",
       "13        0.28248473025714477\n",
       "14         0.3041228576485263\n",
       "15         0.2396150000805766\n",
       "16         0.4526777197995158\n",
       "17         0.5899874161709641\n",
       "18         0.4488420454229167\n",
       "19         0.7380083970716415\n",
       "20          0.355469979114469\n",
       "21         0.4979246366137965\n",
       "22         0.5697995333699827\n",
       "23        0.28252649554280995\n",
       "24        0.32428408760273464\n",
       "25        0.17405559153735956\n",
       "26         0.4591175421688237\n",
       "27         0.3544068877313205\n",
       "28        0.33242254810350386\n",
       "29         0.2607678807977167\n",
       "                 ...         \n",
       "18408       0.252907077015136\n",
       "18409     0.28275153349649274\n",
       "18410     0.23783970066819032\n",
       "18411     0.29402637461058556\n",
       "18412      0.3960110198435872\n",
       "18413     0.11317142204409654\n",
       "18414     0.25394159215019785\n",
       "18415     0.16960539044108827\n",
       "18416       0.253567902752141\n",
       "18417      0.3299915062290127\n",
       "18418     0.15608621476572448\n",
       "18419     0.28203300572008194\n",
       "18420     0.11759057394773516\n",
       "18421    0.047988038457674194\n",
       "18422     0.12699161002502746\n",
       "18423     0.32644667760818064\n",
       "18424      0.2881540930145766\n",
       "18425      0.3302763070092229\n",
       "18426     0.22466824847315076\n",
       "18427     0.20451910847005608\n",
       "18428     0.26027837516342384\n",
       "18429     0.23625729093038925\n",
       "18430     0.18898915410720693\n",
       "18431     0.10636107015031833\n",
       "18432     0.20157273242934745\n",
       "18433      0.2442036860714219\n",
       "18434     0.28379964982655737\n",
       "18435     0.32060530781899615\n",
       "18436      0.6293656234202465\n",
       "18437     0.23255611725992897\n",
       "Name: User_THP_DL_kbps, Length: 18438, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['User_THP_DL_kbps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"data/common_files_HighLoadAnalysis201812200038255c1a038136d32.csv\", encoding = 'gbk')\n",
    "\n",
    "df_clean =  df_raw[['day', 'hour', 'location','Users_RRC_Avg', 'DL_PDSCH_Usage', 'PDCCH_CCE_利用率超过70%的比例',\n",
    "       'DL_Volume_GB', 'UL_PUSCH_Usage', 'UL_Volume_GB', 'RLC时延',\n",
    "       'LTE_User_THP_DL_kpbs', 'LTE_User_THP_UL_kpbs', 'CellTputDl_kbps',\n",
    "       'Uplink Cell Throughput(kbps)', 'MAC层下行BLER', 'MAC层上行BLER',\n",
    "       'RLC层下行重传率(%)', 'RLC层上行重传率(%)', 'SRfail占SR的比例']].copy()\n",
    "\n",
    "df_clean.columns = ['day','hour','cell', 'Users_RRC_Avg', 'PDSCH_Usage_DL',\n",
    "       'PDCCH_CCE_Above_70', 'DL_Volume_GB', 'PUSCH_Usage_UL', 'UL_Volume_GB',\n",
    "       'RLC_Time_Delay', 'User_THP_DL_kbps', 'User_THP_UL_kbps',\n",
    "       'Cell_THP_Dl_kbps', 'Cell_THP_UL_kbps',\n",
    "       'MAC_Retransmission_DL', 'MAC_Retransmission_UL', 'RLC_Retransmission_DL', 'RLC_Retransmission_UL','SRfail_RAatt']\n",
    "\n",
    "# 删除RLC重传率相关的两个指标\n",
    "df_clean.drop(['RLC_Retransmission_DL', 'RLC_Retransmission_UL'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of df_clean before dropna: 585214\n",
      "# of df_clean after dropna: 585214\n"
     ]
    }
   ],
   "source": [
    "print(\"# of df_clean before dropna:\", len(df_clean))\n",
    "df_clean.dropna(inplace = True)\n",
    "print(\"# of df_clean after dropna:\", len(df_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = df_clean.copy()\n",
    "\n",
    "# modify the num of days according to days of data\n",
    "day = 1\n",
    "df_normal = df_normal.groupby(['cell']).filter(lambda group: len(group) == 24 * day)\n",
    "df_normal = df_normal.sort_values(by=['cell','day','hour'])\n",
    "\n",
    "kpi_list = ['Users_RRC_Avg', 'PDSCH_Usage_DL',\n",
    "       'PDCCH_CCE_Above_70', 'DL_Volume_GB', 'PUSCH_Usage_UL', 'UL_Volume_GB',\n",
    "       'RLC_Time_Delay', 'User_THP_DL_kbps', 'User_THP_UL_kbps',\n",
    "       'Cell_THP_Dl_kbps', 'Cell_THP_UL_kbps',\n",
    "       'MAC_Retransmission_DL', 'MAC_Retransmission_UL',\n",
    "       'SRfail_RAatt']\n",
    "# 'RLC_Retransmission_DL', 'RLC_Retransmission_UL'\n",
    "\n",
    "# pdf_90归一化\n",
    "# kpi_list_90pdf = ['Users_RRC_Avg', 'DL_Volume_GB', 'UL_Volume_GB']\n",
    "df_normal_use_pdf90 = df_normal.copy()\n",
    "def getmax(x,y):\n",
    "    if x<y:\n",
    "        return 0\n",
    "    else:\n",
    "        return (x-y)/x\n",
    "for kpi in kpi_list:\n",
    "    if kpi not in ['RLC_Retransmission_DL', 'RLC_Retransmission_UL', 'SRfail_RAatt', 'PDCCH_CCE_Above_70']:\n",
    "        base = np.percentile(df_normal_use_pdf90[kpi],90)\n",
    "        df_normal_use_pdf90[kpi] = df_normal_use_pdf90[kpi].apply(lambda x:getmax(x,base))\n",
    "#     df_normal_use_pdf90[kpi] = (df_normal_use_pdf90[kpi] - base) / df_normal_use_pdf90[kpi]\n",
    "\n",
    "# min-max 归一化\n",
    "# max设为大于均值的三倍标准差\n",
    "df_normal_use_minmax = df_normal.copy()\n",
    "max_use = df_normal[kpi_list].mean() + 3 * df_normal[kpi_list].std()\n",
    "min_use = df_normal[kpi_list].min()\n",
    "df_normal_use_minmax[kpi_list] = (df_normal_use_minmax[kpi_list] - min_use) / (max_use - min_use)\n",
    "\n",
    "# 保存归一化时使用的min max值\n",
    "# df_max = max_use.to_frame(name='MAX')\n",
    "# df_min = max_use.to_frame(name='MIN')\n",
    "# df_min.merge(df_max, left_index=True, right_index=True).to_csv(\"data/min_max_used.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存归一化时使用的min max值\n",
    "df_max_actual = df_normal[kpi_list].max().to_frame(name=\"MAX_ACTUAL\")\n",
    "df_min_actual = df_normal[kpi_list].min().to_frame(name=\"MIN_ACTUAL\")\n",
    "df_mean = df_normal[kpi_list].mean().to_frame(name=\"MEAN\")\n",
    "df_max_used = max_use.to_frame(name='MAX_USED')\n",
    "df_min_used = min_use.to_frame(name='MIN_USED')\n",
    "df_mean.join(df_min_actual).join(df_max_actual).join(df_min_used).join(df_max_used).to_csv(\"data/min_max_used.csv\")\n",
    "# df_min_actual.merge(df_max_actual, left_index=True, right_index=True)\n",
    "\n",
    "# df_min_used.merge(df_max_used, left_index=True, right_index=True).to_csv(\"data/min_max_used.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成wide table并储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_kpis = len(kpi_list)\n",
    "nb_hours = 24\n",
    "nb_features = nb_kpis * nb_hours\n",
    "\n",
    "def gen_save_wide_table(df_normal, name):\n",
    "    \"\"\"\n",
    "    generate wide table per given datasets after normalization\n",
    "    \"\"\"\n",
    "    df_normal_wide = pd.DataFrame(df_normal.groupby(['cell', 'day', 'hour']).sum().unstack(['day','hour']))\n",
    "    df_normal_wide.to_csv(\"data/data_wide_{}.csv\".format(name))\n",
    "\n",
    "gen_save_wide_table(df_normal_use_minmax, name=\"min_max\")\n",
    "gen_save_wide_table(df_normal_use_pdf90, name=\"pdf90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
